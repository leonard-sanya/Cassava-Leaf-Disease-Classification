{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":77142,"databundleVersionId":8400328,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # !export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n# import os\n\n# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:14.410369Z","iopub.execute_input":"2024-05-19T11:57:14.411405Z","iopub.status.idle":"2024-05-19T11:57:14.416022Z","shell.execute_reply.started":"2024-05-19T11:57:14.411365Z","shell.execute_reply":"2024-05-19T11:57:14.414953Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Imports\nimport os\nimport sys\nimport glob\nimport torch\nimport timm\nimport torchvision\n\nimport numpy    as np\nimport datetime as dt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot   as plt\n\nfrom PIL               import Image\nfrom torch.utils.data  import Dataset\nfrom torch.autograd    import Variable\nfrom torch.optim       import lr_scheduler\n\nfrom torch.utils.data  import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision       import transforms, datasets, models\nfrom os                import listdir, makedirs, getcwd, remove\nfrom os.path           import isfile, join, abspath, exists, isdir, expanduser","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:14.417313Z","iopub.execute_input":"2024-05-19T11:57:14.417662Z","iopub.status.idle":"2024-05-19T11:57:22.426984Z","shell.execute_reply.started":"2024-05-19T11:57:14.417629Z","shell.execute_reply":"2024-05-19T11:57:22.425903Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntrain_path = \"/kaggle/input/ammi-2024-computer-vision/train/train\"\ntest_path = \"/kaggle/input/ammi-2024-computer-vision/test/test\"\n# extraimage_path = join(data_path, \"extraimages/extraimages\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:22.429455Z","iopub.execute_input":"2024-05-19T11:57:22.429834Z","iopub.status.idle":"2024-05-19T11:57:22.456752Z","shell.execute_reply.started":"2024-05-19T11:57:22.429806Z","shell.execute_reply":"2024-05-19T11:57:22.455526Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Transformations for both the training and testing data\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\n\n# Do data transforms here, Try many others\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(256),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor()])\n\ntest_transforms = transforms.Compose([ transforms.Resize(255),\n                                       transforms.CenterCrop(256),\n                                       transforms.ToTensor()])\n\nnormalize = transforms.Normalize(mean=mean, std=std)\n\nclass CassavaDataset(Dataset):\n    def __init__(self, path, transform=None):\n        self.classes = os.listdir(path)\n        self.path = [f\"{path}/{className}\" for className in self.classes]\n        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n        self.transform = transform\n\n        files = []\n        for i, className in enumerate(self.classes):\n            for fileName in self.file_list[i]:\n                files.append([i, className, fileName])\n        self.file_list = files\n        files = None\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        fileName = self.file_list[idx][2]\n        classCategory = self.file_list[idx][0]\n        im = Image.open(fileName)\n        if self.transform:\n            im = self.transform(im)\n            \n        return im.view(3, 256, 256), classCategory\n    \ntrain_data = CassavaDataset(train_path, transform=train_transforms)\ntest_data = CassavaDataset(test_path, transform=test_transforms) \n\n\nvalidation_split = .2\nshuffle_dataset = True\nrandom_seed= 42\n\n# Creating data indices for training and validation splits:\ndataset_size = len(train_data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\n\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\n\ntrain_set = torch.utils.data.DataLoader(train_data, batch_size=32,\n                                             sampler=train_sampler)\ntest_set = torch.utils.data.DataLoader(train_data, batch_size=32,\n                                             sampler=valid_sampler)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=32)\n\ntrain_len = len(train_set)*32\nvalid_len = len(test_set)*32","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:22.458559Z","iopub.execute_input":"2024-05-19T11:57:22.459037Z","iopub.status.idle":"2024-05-19T11:57:22.525355Z","shell.execute_reply.started":"2024-05-19T11:57:22.458988Z","shell.execute_reply":"2024-05-19T11:57:22.524195Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self, num_classes, weights=models.MobileNet_V2_Weights.DEFAULT):\n        super().__init__()\n        \n        # Load the pre-trained MobileNetV2 model\n        self.mobilenet = models.mobilenet_v2(weights=weights)\n        \n        # Modify the final fully connected layer to match the number of classes\n        num_ftrs = self.mobilenet.classifier[1].in_features\n        self.mobilenet.classifier[1] = nn.Linear(num_ftrs, num_classes)\n    \n    def forward(self, x):\n        return self.mobilenet(x)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:22.526671Z","iopub.execute_input":"2024-05-19T11:57:22.527023Z","iopub.status.idle":"2024-05-19T11:57:22.534581Z","shell.execute_reply.started":"2024-05-19T11:57:22.526995Z","shell.execute_reply":"2024-05-19T11:57:22.533439Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"num_classes = 5\nmodel = Classifier(num_classes)\n#print(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:22.535869Z","iopub.execute_input":"2024-05-19T11:57:22.536235Z","iopub.status.idle":"2024-05-19T11:57:23.062313Z","shell.execute_reply.started":"2024-05-19T11:57:22.536209Z","shell.execute_reply":"2024-05-19T11:57:23.060983Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n100%|██████████| 13.6M/13.6M [00:00<00:00, 77.2MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(),lr = 0.001,momentum= 0.9)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:23.064054Z","iopub.execute_input":"2024-05-19T11:57:23.064885Z","iopub.status.idle":"2024-05-19T11:57:23.071220Z","shell.execute_reply.started":"2024-05-19T11:57:23.064853Z","shell.execute_reply":"2024-05-19T11:57:23.070000Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T13:32:58.710126Z","iopub.execute_input":"2024-05-19T13:32:58.710559Z","iopub.status.idle":"2024-05-19T13:32:58.719633Z","shell.execute_reply.started":"2024-05-19T13:32:58.710525Z","shell.execute_reply":"2024-05-19T13:32:58.718375Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Classifier(\n  (mobilenet): MobileNetV2(\n    (features): Sequential(\n      (0): Conv2dNormActivation(\n        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n      (1): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (6): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (7): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (8): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (9): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (10): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (11): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (12): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (13): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (14): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (15): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (16): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (17): InvertedResidual(\n        (conv): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU6(inplace=True)\n          )\n          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (18): Conv2dNormActivation(\n        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU6(inplace=True)\n      )\n    )\n    (classifier): Sequential(\n      (0): Dropout(p=0.2, inplace=False)\n      (1): Linear(in_features=1280, out_features=5, bias=True)\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(model, criterion, data_loader1, optimizer, num_epochs):\n    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n    model = model.to(device)\n    # Make sure model is in training mode.\n    #model.train()\n\n    model.train()\n    for epoch in range(num_epochs):\n        total_correct = 0\n        running_loss = 0\n\n        # Training step\n        for i, (inputs, labels) in enumerate(data_loader1):\n            inputs , labels  = inputs.to(device),labels.to(device)\n\n            output = model(inputs)\n            #print(output.logits)\n            output_idx = torch.argmax(output,dim =-1)\n            total_correct +=(labels==output_idx).sum().item()\n            optimizer.zero_grad()\n            loss = criterion(output, labels)\n            running_loss+=loss.item()*inputs.size(0)\n            loss.backward()\n            optimizer.step()\n\n        # Print out progress at the end of epoch.\n        print(f\"Epoch {epoch}, Train Loss: {running_loss/train_len}, Accuracy: {(total_correct/train_len)*100}%\")\n    print(\"Finished Training\")\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:23.072812Z","iopub.execute_input":"2024-05-19T11:57:23.074115Z","iopub.status.idle":"2024-05-19T11:57:23.083606Z","shell.execute_reply.started":"2024-05-19T11:57:23.074076Z","shell.execute_reply":"2024-05-19T11:57:23.082597Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def test(model, test_set):\n\n    with torch.no_grad():\n        model.eval()\n        total_loss = 0\n        total_correct = 0\n\n        # Testing step\n        for inputs, labels in test_set:\n            inputs , labels  = inputs.to(device),labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            total_loss +=loss.item()*inputs.size(0)\n            output_idx = torch.argmax(outputs,dim =-1)\n            total_correct +=(labels==output_idx).sum().item()\n\n        print(f\"Accuracy: {(total_correct/valid_len)*100}%  Loss: {total_loss/valid_len}\")\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:23.086224Z","iopub.execute_input":"2024-05-19T11:57:23.086541Z","iopub.status.idle":"2024-05-19T11:57:23.098156Z","shell.execute_reply.started":"2024-05-19T11:57:23.086516Z","shell.execute_reply":"2024-05-19T11:57:23.097014Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100 #100\ntrain(model, criterion, train_set, optimizer, num_epochs=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T11:57:23.099588Z","iopub.execute_input":"2024-05-19T11:57:23.100057Z","iopub.status.idle":"2024-05-19T13:18:09.523490Z","shell.execute_reply.started":"2024-05-19T11:57:23.100021Z","shell.execute_reply":"2024-05-19T13:18:09.522360Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 0, Train Loss: 1.2117931590690998, Accuracy: 50.63820422535211%\nEpoch 1, Train Loss: 0.9309834094691865, Accuracy: 65.2068661971831%\nEpoch 2, Train Loss: 0.7838512021182499, Accuracy: 71.34683098591549%\nEpoch 3, Train Loss: 0.6733582268180457, Accuracy: 76.01232394366197%\nEpoch 4, Train Loss: 0.5942497103094635, Accuracy: 79.00528169014085%\nEpoch 5, Train Loss: 0.5595888918344404, Accuracy: 79.44542253521126%\nEpoch 6, Train Loss: 0.5386096523733626, Accuracy: 80.69982394366197%\nEpoch 7, Train Loss: 0.5087624413459758, Accuracy: 82.02024647887323%\nEpoch 8, Train Loss: 0.48613857952090844, Accuracy: 83.51672535211267%\nEpoch 9, Train Loss: 0.4661049415147535, Accuracy: 83.38468309859155%\nEpoch 10, Train Loss: 0.45761181296072373, Accuracy: 83.86883802816901%\nEpoch 11, Train Loss: 0.44305669691111943, Accuracy: 84.33098591549296%\nEpoch 12, Train Loss: 0.43081878647077043, Accuracy: 85.34330985915493%\nEpoch 13, Train Loss: 0.4218558152927689, Accuracy: 85.12323943661971%\nEpoch 14, Train Loss: 0.4121441596620519, Accuracy: 85.45334507042254%\nEpoch 15, Train Loss: 0.4053129561927537, Accuracy: 85.49735915492957%\nEpoch 16, Train Loss: 0.40809432608665713, Accuracy: 85.67341549295774%\nEpoch 17, Train Loss: 0.3917199823690552, Accuracy: 86.13556338028168%\nEpoch 18, Train Loss: 0.3935992307829815, Accuracy: 86.15757042253522%\nEpoch 19, Train Loss: 0.38660183876529863, Accuracy: 86.09154929577466%\nEpoch 20, Train Loss: 0.36643495358539824, Accuracy: 86.88380281690141%\nEpoch 21, Train Loss: 0.36199548642452756, Accuracy: 87.01584507042254%\nEpoch 22, Train Loss: 0.3608374740128261, Accuracy: 87.30193661971832%\nEpoch 23, Train Loss: 0.35547732241766555, Accuracy: 86.7737676056338%\nEpoch 24, Train Loss: 0.34170173662124387, Accuracy: 87.83010563380282%\nEpoch 25, Train Loss: 0.34047083334315204, Accuracy: 88.44630281690141%\nEpoch 26, Train Loss: 0.3340879724505292, Accuracy: 87.52200704225352%\nEpoch 27, Train Loss: 0.3385922389832968, Accuracy: 87.27992957746478%\nEpoch 28, Train Loss: 0.32949959723160827, Accuracy: 88.24823943661971%\nEpoch 29, Train Loss: 0.32631231668654465, Accuracy: 88.24823943661971%\nEpoch 30, Train Loss: 0.31875247509435184, Accuracy: 88.40228873239437%\nEpoch 31, Train Loss: 0.3165287836585981, Accuracy: 88.68838028169014%\nEpoch 32, Train Loss: 0.30517006595946955, Accuracy: 89.26056338028168%\nEpoch 33, Train Loss: 0.2959162652767985, Accuracy: 89.32658450704226%\nEpoch 34, Train Loss: 0.2977178422209453, Accuracy: 89.41461267605634%\nEpoch 35, Train Loss: 0.30111362635564637, Accuracy: 89.30457746478874%\nEpoch 36, Train Loss: 0.28418854632559165, Accuracy: 90.25088028169014%\nEpoch 37, Train Loss: 0.28109299795682424, Accuracy: 89.63468309859155%\nEpoch 38, Train Loss: 0.29402110364917716, Accuracy: 88.97447183098592%\nEpoch 39, Train Loss: 0.2800857726497654, Accuracy: 89.7887323943662%\nEpoch 40, Train Loss: 0.28078897629248006, Accuracy: 90.07482394366197%\nEpoch 41, Train Loss: 0.2716422037969173, Accuracy: 90.09683098591549%\nEpoch 42, Train Loss: 0.25025504368560675, Accuracy: 91.0431338028169%\nEpoch 43, Train Loss: 0.2580348512708721, Accuracy: 90.5149647887324%\nEpoch 44, Train Loss: 0.2668462559633272, Accuracy: 90.25088028169014%\nEpoch 45, Train Loss: 0.26268652070339926, Accuracy: 90.84507042253522%\nEpoch 46, Train Loss: 0.24247967380977853, Accuracy: 91.3512323943662%\nEpoch 47, Train Loss: 0.24103791222737078, Accuracy: 90.97711267605634%\nEpoch 48, Train Loss: 0.2584187590294111, Accuracy: 90.47095070422534%\nEpoch 49, Train Loss: 0.24778242321015978, Accuracy: 90.97711267605634%\nEpoch 50, Train Loss: 0.23740932076159393, Accuracy: 91.39524647887323%\nEpoch 51, Train Loss: 0.2320104768429227, Accuracy: 91.32922535211267%\nEpoch 52, Train Loss: 0.23945111242241005, Accuracy: 91.0431338028169%\nEpoch 53, Train Loss: 0.23617634488086045, Accuracy: 91.54929577464789%\nEpoch 54, Train Loss: 0.2307868401034617, Accuracy: 91.52728873239437%\nEpoch 55, Train Loss: 0.24881665832625413, Accuracy: 90.82306338028168%\nEpoch 56, Train Loss: 0.21344682031875134, Accuracy: 92.0774647887324%\nEpoch 57, Train Loss: 0.2142426276146631, Accuracy: 92.1875%\nEpoch 58, Train Loss: 0.22208608591824142, Accuracy: 91.98943661971832%\nEpoch 59, Train Loss: 0.2148294654317384, Accuracy: 91.85739436619718%\nEpoch 60, Train Loss: 0.20371592452775844, Accuracy: 92.36355633802818%\nEpoch 61, Train Loss: 0.2175612880071153, Accuracy: 92.23151408450704%\nEpoch 62, Train Loss: 0.19790883654807234, Accuracy: 92.42957746478874%\nEpoch 63, Train Loss: 0.1935434696284241, Accuracy: 92.71566901408451%\nEpoch 64, Train Loss: 0.19847433892091815, Accuracy: 92.4955985915493%\nEpoch 65, Train Loss: 0.216468487426796, Accuracy: 91.65933098591549%\nEpoch 66, Train Loss: 0.202417399694907, Accuracy: 92.23151408450704%\nEpoch 67, Train Loss: 0.19420028797967334, Accuracy: 92.64964788732394%\nEpoch 68, Train Loss: 0.20593481941122405, Accuracy: 92.20950704225352%\nEpoch 69, Train Loss: 0.20373614091413017, Accuracy: 92.34154929577466%\nEpoch 70, Train Loss: 0.1911500925624507, Accuracy: 93.06778169014085%\nEpoch 71, Train Loss: 0.18919700351346966, Accuracy: 92.97975352112677%\nEpoch 72, Train Loss: 0.19014269474592113, Accuracy: 92.95774647887323%\nEpoch 73, Train Loss: 0.18679748967447332, Accuracy: 93.08978873239437%\nEpoch 74, Train Loss: 0.17875765276659594, Accuracy: 93.17781690140845%\nEpoch 75, Train Loss: 0.17578716291127805, Accuracy: 93.15580985915493%\nEpoch 76, Train Loss: 0.17514746057027034, Accuracy: 93.81602112676056%\nEpoch 77, Train Loss: 0.1884265603287749, Accuracy: 92.93573943661971%\nEpoch 78, Train Loss: 0.16624502288046436, Accuracy: 93.55193661971832%\nEpoch 79, Train Loss: 0.1761589337625659, Accuracy: 93.68397887323944%\nEpoch 80, Train Loss: 0.17580711945209285, Accuracy: 93.57394366197182%\nEpoch 81, Train Loss: 0.16785909809355795, Accuracy: 93.3318661971831%\nEpoch 82, Train Loss: 0.1825602901279664, Accuracy: 92.64964788732394%\nEpoch 83, Train Loss: 0.1720852542612833, Accuracy: 93.37588028169014%\nEpoch 84, Train Loss: 0.16396095698640328, Accuracy: 93.77200704225352%\nEpoch 85, Train Loss: 0.17157827324929162, Accuracy: 93.61795774647888%\nEpoch 86, Train Loss: 0.16072870085333985, Accuracy: 93.92605633802818%\nEpoch 87, Train Loss: 0.1503887470700109, Accuracy: 94.32218309859155%\nEpoch 88, Train Loss: 0.16764370066566314, Accuracy: 94.19014084507043%\nEpoch 89, Train Loss: 0.1596686315065263, Accuracy: 93.6399647887324%\nEpoch 90, Train Loss: 0.1465742338570097, Accuracy: 94.23415492957746%\nEpoch 91, Train Loss: 0.16231122312568863, Accuracy: 93.70598591549296%\nEpoch 92, Train Loss: 0.1611289677380676, Accuracy: 93.72799295774648%\nEpoch 93, Train Loss: 0.15844983023486403, Accuracy: 93.97007042253522%\nEpoch 94, Train Loss: 0.15929795103147626, Accuracy: 94.10211267605634%\nEpoch 95, Train Loss: 0.1500147044884933, Accuracy: 94.34419014084507%\nEpoch 96, Train Loss: 0.15218890465887813, Accuracy: 94.1681338028169%\nEpoch 97, Train Loss: 0.15706037665253283, Accuracy: 93.83802816901408%\nEpoch 98, Train Loss: 0.1473773586380125, Accuracy: 94.30017605633803%\nEpoch 99, Train Loss: 0.15490498242270148, Accuracy: 94.19014084507043%\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"test(model,test_set)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T13:25:23.509415Z","iopub.execute_input":"2024-05-19T13:25:23.509878Z","iopub.status.idle":"2024-05-19T13:25:34.827680Z","shell.execute_reply.started":"2024-05-19T13:25:23.509845Z","shell.execute_reply":"2024-05-19T13:25:34.826681Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Accuracy: 85.06944444444444%  Loss: 0.4278522837234454\n","output_type":"stream"}]},{"cell_type":"code","source":"# Make submission here\nsample_path = \"/kaggle/input/ammi-2024-computer-vision/sample_submission_file.csv\"\nimport pandas as pd\n\ndef test_mode(model, data_loader):\n    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n    # Make sure the model is in evaluation mode.\n    preds = []\n    model.eval()\n    # We do not need to maintain intermediate activations while testing.\n    with torch.no_grad():\n        \n        # Loop over test data.\n        for features, _ in data_loader:\n          \n            # Forward pass.\n            output = model(features.to(device))\n            \n            # Get the label corresponding to the highest predicted probability.\n            pred = output.argmax(dim=1, keepdim=True)\n            preds.append(pred.cpu().data.numpy())\n            \n    return preds\n\npreds = test_mode(model, test_loader)\npreds = [item.item() for sublist in preds for item in sublist]\n\n# Extract filenames from the ImageFolder object\nname = [os.path.basename(img_path) for _, _, img_path in test_data.file_list]\nsample = pd.read_csv(sample_path)\nmapping = {0: 'cmd', 1: 'cbb', 2: 'cbsd', 3: 'healthy', 4: 'cgm'}\nnew_preds = [mapping[pred] for pred in preds]\nsample['Category'] = name\nsample['Id'] = new_preds\nsample[\"Category\"],sample[\"Id\"] = sample[\"Id\"],sample[\"Category\"]\n\n\nsample.to_csv('MobileNet13.csv', index=False)\nsample.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T13:25:58.946212Z","iopub.execute_input":"2024-05-19T13:25:58.946634Z","iopub.status.idle":"2024-05-19T13:26:54.045634Z","shell.execute_reply.started":"2024-05-19T13:25:58.946606Z","shell.execute_reply":"2024-05-19T13:26:54.044604Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"  Category                 Id\n0      cgm  test-img-1448.jpg\n1      cmd   test-img-768.jpg\n2      cmd  test-img-3481.jpg\n3      cmd  test-img-1475.jpg\n4      cgm  test-img-2498.jpg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cgm</td>\n      <td>test-img-1448.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cmd</td>\n      <td>test-img-768.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cmd</td>\n      <td>test-img-3481.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cmd</td>\n      <td>test-img-1475.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cgm</td>\n      <td>test-img-2498.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"4+8","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
